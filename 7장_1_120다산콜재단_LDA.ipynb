{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swKyungbock/2023MLwithTextData/blob/main/7%EC%9E%A5_1_120%EB%8B%A4%EC%82%B0%EC%BD%9C%EC%9E%AC%EB%8B%A8_LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz2aYwDao1Yk"
      },
      "source": [
        "## '120다산콜재단' 토픽 모델링\n",
        "- 비지도학습\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kpwaWyzo1Yr"
      },
      "source": [
        "## 라이브러리 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jEmmKL0o1Ys"
      },
      "outputs": [],
      "source": [
        "# 필요 라이브러리를 로드\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MzjjX3ho1Ys"
      },
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZd0hR-Vo1Yu"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"https://bit.ly/seoul-120-text-csv\")\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbjUJ2qapEVG"
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw4p_dnIo1Yw"
      },
      "source": [
        "## 문서 만들기\n",
        "* 제목과 내용을 함께 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ9GAlhuo1Yx"
      },
      "outputs": [],
      "source": [
        "df[\"문서\"] = df[\"제목\"] + \" \" + df[\"내용\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "O-UxX3rkMB8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMII7R0go1Yx"
      },
      "source": [
        "## 벡터화\n",
        "\n",
        "* BOW\n",
        "* CountVectorizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94FBGEqOo1Yy"
      },
      "outputs": [],
      "source": [
        "# 단어들의 출현 빈도(frequency)로 여러 문서들을 벡터화하기 위해 CountVectorizer 사용\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(stop_words=[\"돋움\", \"경우\", \"또는\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft2MvWD57MjT"
      },
      "source": [
        "### 참고: fit, transform, fit_transfrom의 차이점\n",
        "- fit(): 원시 문서에 있는 모든 토큰의 어휘 사전을 배운다\n",
        "- transform(): 문서를 문서 용어 매트릭스로 변환, transform 이후엔 매트릭스로 변환되어 숫자형태로 변경\n",
        "- fit_transform(): 어휘 사전을 배우고 문서 용어 매트릭스를 반환, fit 다음에 변환이 오는 것과 동일하지만 더 효율적으로 구현\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YueqXKDbo1Yy"
      },
      "outputs": [],
      "source": [
        "# fit_transform을 사용하여 문장에서 노출되는 feature(특징이 될만한 단어) 수를 합한 변수 Document Term Matrix(이하 dtm)를 생성\n",
        "dtm_cv = cv.fit_transform(df[\"문서\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr_Gj0Bro1Yy"
      },
      "outputs": [],
      "source": [
        "# cv.vocabulary_ 를 봅니다.\n",
        "cv.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dRGKkOamU4w"
      },
      "outputs": [],
      "source": [
        "cv_cols = cv.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6sZ_cIdo1Yz"
      },
      "outputs": [],
      "source": [
        "#단어 가방에 있는 모든 단어를 행렬값으로 변환\n",
        "# '있는','있습니다'와 같은 고빈도 단어를 불용어로 다룰 것인지 고려하기\n",
        "pd.DataFrame(dtm_cv.toarray(), columns=cv_cols).sum().sort_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZKMAZ5go1Yz"
      },
      "source": [
        "## 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)\n",
        "\n",
        "* API documentation: https://pyldavis.readthedocs.io/en/latest/modules/API.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj6AiX1Po1Y0"
      },
      "outputs": [],
      "source": [
        "# 정답인 '분류'의 유일한 값을 확인하여 주제 수를 확인\n",
        "df[\"분류\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQBuD_fJo1Y0"
      },
      "outputs": [],
      "source": [
        "# 주어진 문서에 대하여 각 문서에 어떤 주제들이 존재하는지를 확인하는 잠재 디리클레 분석(LDA)을 불러옴\n",
        "# n_components에 넣을 하이퍼파라미터 NUM_TOPICS로 주제수를 설정(기본값=10)\n",
        "# max_iter는 훈련 데이터(epoch라고도 함)에 대한 최대 패스 수(기본값=10)\n",
        "\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "NUM_TOPICS = 10\n",
        "LDA_model = LatentDirichletAllocation(n_components=NUM_TOPICS, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGUq-nhkmU4x"
      },
      "outputs": [],
      "source": [
        "# LDA_model 에 dtm_cv 를 넣어 학습\n",
        "LDA_model.fit(dtm_cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bduBjLQZo1Y1"
      },
      "source": [
        "## TF-IDF(Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "## TfidfVectorizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEUNepLOo1Y1"
      },
      "outputs": [],
      "source": [
        "# TF-IDF 방식으로 단어의 가중치를 조정한 BOW 인코딩하여 벡터화하기 위해 TfidfVectorizer를 사용\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=[\"돋움\", \"경우\", \"또는\", \"있습니다\", \"있는\", \"합니다\"])\n",
        "tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKEXeuKQo1Y1"
      },
      "outputs": [],
      "source": [
        "# 문장에서 노출되는 feature(특징이 될만한 단어) 수를 합한 변수 Document Term Matrix(이하 dtm)를 생성\n",
        "dtm_tfidf = tfidf.fit_transform(df[\"문서\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLkWfsggo1Y1"
      },
      "outputs": [],
      "source": [
        "# tfidf.vocabulary_\n",
        "cols_tfidf = tfidf.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8W95ppMo1Y2"
      },
      "outputs": [],
      "source": [
        "# dtm_tf를 axis=0(수직 방향으로) 기준으로 합계를 낸 dist 변수를 생성\n",
        "# dist 변수를 vocabulary_ 순으로 정렬하여 비율을 확인\n",
        "dist = np.sum(dtm_tfidf, axis=0)\n",
        "pd.DataFrame(dist, columns=cols_tfidf).T.sort_values(by=0).tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l61luP9mo1Y2"
      },
      "outputs": [],
      "source": [
        "# 각 row에서 전체 단어가방에 있는 어휘에서 등장하는 단어에 대한 가중치를 적용한 vector를 확인\n",
        "# toarray()로 희소 행렬(sparse matrix, 행렬의 값이 대부분 '0'인 행렬)을 NumPy array 배열로 변환하여 값을 확인\n",
        "pd.DataFrame(dtm_tfidf.toarray(), columns=cols_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SfyYdvZo1Y3"
      },
      "source": [
        "## 코사인 유사도\n",
        "* API Document: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC98n4w5o1Y3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_simple_pair = cosine_similarity(dtm_tfidf[0] , dtm_tfidf)\n",
        "result_list = similarity_simple_pair.tolist()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJFB-n4Lo1Y3"
      },
      "outputs": [],
      "source": [
        "df[\"유사도\"] = result_list\n",
        "df[[\"분류\", \"제목\", \"유사도\"]].sort_values(by=\"유사도\", ascending=False).head(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "256px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}